{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustav2k22/GRP12_BCS206_StudentDepression/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgjR2sl0nq04"
      },
      "outputs": [],
      "source": [
        "# Adding all needed libraries\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn plotly\n",
        "\n",
        "# Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, log_loss, roc_auc_score,\n",
        "                            precision_score, recall_score, f1_score,\n",
        "                            confusion_matrix, classification_report, roc_curve)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setting style for better visual plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/raw/student_depression_dataset.csv')\n",
        "\n",
        "# Basic dataset information\n",
        "print(\"📊 DATASET OVERVIEW\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(\"\\n📋 First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n📈 Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n📊 Statistical Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n🔍 Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Based on your screenshot, the target column appears to be 'Depression'\n",
        "target_column = 'Depression'\n",
        "print(f\"\\n🎯 Target Column: {target_column}\")\n",
        "print(f\"Target Distribution:\")\n",
        "if target_column in df.columns:\n",
        "    print(df[target_column].value_counts())\n",
        "else:\n",
        "    print(\"⚠️ Please check the exact target column name\")"
      ],
      "metadata": {
        "id": "0BefHtSstmD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🎯 DATASET JUSTIFICATION\")\n",
        "print(\"=\"*50)\n",
        "print(\"\"\"\n",
        "📌 DATASET: Student Depression Dataset\n",
        "\n",
        "🔍 RELEVANCE TO PREDICTIVE TASK:\n",
        "- Mental health is a critical issue among students globally\n",
        "- Early detection of depression can enable timely intervention\n",
        "- Dataset contains comprehensive student information including:\n",
        "  * Demographics: Age, Gender, City\n",
        "  * Academic factors: Academic Pressure, CGPA, Study Satisfaction\n",
        "  * Social factors: Work Pressure, Job Satisfaction\n",
        "  * Health factors: Sleep Duration, Dietary Habits\n",
        "  * Mental health indicators: Suicidal thoughts, Family History\n",
        "- Classification problem: Predict presence/absence of depression\n",
        "- Real-world application with significant social impact\n",
        "\n",
        "🎯 PREDICTIVE OBJECTIVE:\n",
        "Build an advanced ensemble model to classify students as having depression based on:\n",
        "- Academic performance and pressure levels\n",
        "- Social and work-related stress factors\n",
        "- Lifestyle and health indicators\n",
        "- Demographics and family history\n",
        "- Sleep patterns and dietary habits\n",
        "\"\"\")\n",
        "\n",
        "# Analyze target variable using your dataset structure\n",
        "target_col = 'Depression'  # Based on your screenshot\n",
        "if target_col in df.columns:\n",
        "    print(f\"\\n📊 Target Variable Distribution:\")\n",
        "    print(df[target_col].value_counts())\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Create subplot for better visualization\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Count plot\n",
        "    df[target_col].value_counts().plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
        "    ax1.set_title('Distribution of Depression Cases')\n",
        "    ax1.set_xlabel('Depression Status')\n",
        "    ax1.set_ylabel('Count')\n",
        "    ax1.tick_params(axis='x', rotation=0)\n",
        "\n",
        "    # Pie chart\n",
        "    df[target_col].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%', colors=['skyblue', 'lightcoral'])\n",
        "    ax2.set_title('Depression Cases Percentage')\n",
        "    ax2.set_ylabel('')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️ Please identify the correct target column name in your dataset\")"
      ],
      "metadata": {
        "id": "ESJzoePVullg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔧 DATA PREPROCESSING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Handling the preprocessing properly\n",
        "print(\"Original dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Target column\n",
        "target_col = 'Depression'\n",
        "\n",
        "# Handle missing values if any\n",
        "print(\"Checking for missing values...\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "# Fill missing values if they exist\n",
        "if missing_values.sum() > 0:\n",
        "    # Fill numerical columns with median\n",
        "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
        "\n",
        "    # Fill categorical columns with mode\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        if col != target_col:\n",
        "            df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"Encoding categorical variables...\")\n",
        "label_encoders = {}\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col != target_col:\n",
        "        le = LabelEncoder()\n",
        "        df[col] = le.fit_transform(df[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"Encoded {col}: {le.classes_}\")\n",
        "\n",
        "# Prepare features and target\n",
        "X = df.drop([target_col], axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "# Encode target variable if it's categorical\n",
        "if y.dtype == 'object':\n",
        "    le_target = LabelEncoder()\n",
        "    y = le_target.fit_transform(y)\n",
        "    print(f\"Target classes: {le_target.classes_}\")\n",
        "\n",
        "print(f\"\\n✅ Features shape: {X.shape}\")\n",
        "print(f\"✅ Target shape: {y.shape}\")\n",
        "print(f\"✅ Feature columns: {X.columns.tolist()}\")\n",
        "print(f\"✅ Target distribution: {np.bincount(y)}\")"
      ],
      "metadata": {
        "id": "YGecv0DRu2fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🤖 ENSEMBLE LEARNING/ ADVANCED STACKING MODEL DEVELOPMENT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Import additional libraries for stacking\n",
        "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"✅ Training set: {X_train_scaled.shape}\")\n",
        "print(f\"✅ Testing set: {X_test_scaled.shape}\")\n",
        "\n",
        "# Define base models for stacking\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('nb', GaussianNB())\n",
        "]\n",
        "\n",
        "# Define meta-model (final estimator)\n",
        "meta_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Create stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_model,\n",
        "    cv=5,  # 5-fold cross-validation for generating meta-features\n",
        "    stack_method='predict_proba',  # Use probabilities for meta-features\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"🚀 Training Stacking Classifier...\")\n",
        "print(\"Base Models:\")\n",
        "for name, model in base_models:\n",
        "    print(f\"  • {name}: {model.__class__.__name__}\")\n",
        "print(f\"Meta Model: {meta_model.__class__.__name__}\")\n",
        "\n",
        "# Train the Ensemble/ stacking classifier\n",
        "stacking_clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\n✅ Ensemble/ Stacking Classifier trained successfully!\")\n",
        "\n",
        "# Also train individual base models for comparison\n",
        "print(\"\\n📊 INDIVIDUAL BASE MODEL PERFORMANCE:\")\n",
        "individual_results = {}\n",
        "\n",
        "for name, model in base_models:\n",
        "    # Train individual model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    individual_results[name] = {'accuracy': accuracy, 'auc': auc, 'f1': f1}\n",
        "    print(f\"{name.upper():>3}: Accuracy={accuracy:.4f}, AUC={auc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "# Test stacking classifier\n",
        "print(f\"\\n🏆 ENSEMBLE/ STACKING CLASSIFIER PERFORMANCE:\")\n",
        "stacking_pred = stacking_clf.predict(X_test_scaled)\n",
        "stacking_pred_proba = stacking_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "stacking_accuracy = accuracy_score(y_test, stacking_pred)\n",
        "stacking_auc = roc_auc_score(y_test, stacking_pred_proba)\n",
        "stacking_f1 = f1_score(y_test, stacking_pred)\n",
        "\n",
        "print(f\"STACKING: Accuracy={stacking_accuracy:.4f}, AUC={stacking_auc:.4f}, F1={stacking_f1:.4f}\")\n",
        "\n",
        "# Set the best model as our stacking classifier for further analysis\n",
        "final_model = stacking_clf\n",
        "best_model_name = \"Ensemble/ Stacking Classifier\"\n",
        "\n",
        "print(f\"\\n🎯 Selected Model: {best_model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni4K8HJ1vOBq",
        "outputId": "0b8bb87c-3d7d-4b3c-980a-88164350b0d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 ADVANCED STACKING MODEL DEVELOPMENT\n",
            "==================================================\n",
            "✅ Training set: (22320, 17)\n",
            "✅ Testing set: (5581, 17)\n",
            "🚀 Training Stacking Classifier...\n",
            "Base Models:\n",
            "  • rf: RandomForestClassifier\n",
            "  • svm: SVC\n",
            "  • gb: GradientBoostingClassifier\n",
            "  • knn: KNeighborsClassifier\n",
            "  • nb: GaussianNB\n",
            "Meta Model: LogisticRegression\n",
            "\n",
            "✅ Stacking Classifier trained successfully!\n",
            "\n",
            "📊 INDIVIDUAL BASE MODEL PERFORMANCE:\n",
            " RF: Accuracy=0.8396, AUC=0.9134, F1=0.8648\n",
            "SVM: Accuracy=0.8420, AUC=0.9100, F1=0.8680\n",
            " GB: Accuracy=0.8464, AUC=0.9189, F1=0.8709\n",
            "KNN: Accuracy=0.8138, AUC=0.8701, F1=0.8446\n",
            " NB: Accuracy=0.5852, AUC=0.9144, F1=0.7383\n",
            "\n",
            "🏆 STACKING CLASSIFIER PERFORMANCE:\n",
            "STACKING: Accuracy=0.8439, AUC=0.9189, F1=0.8686\n",
            "\n",
            "🎯 Selected Model: Stacking Classifier\n"
          ]
        }
      ]
    }
  ]
}